---
title: "R for Data Exploration and Visualizations" 
author: "Alex Lucchesi"    
date: "March 31st, 2023"
editor_options: 
  markdown: 
    wrap: 72
---

# **R Libraries: ggplot2, dplyr**

## Installation

The package `tidyverse` contains a group of packages that are useful for
when we want to focus on Data Analytics.

The R library `ggplot2` is a super useful tool we can use to create
visualizations and explore our data.

The R library `dplyr` is a super useful too we can use to explore and
manipulate our data.

```{r}
install.packages("tidyverse")
library("tidyverse")
```

More things we can do to get more information on R and what we're doing:

```{r}
?tidyverse
help(tidyverse)
```

We'll need a few more packages for our exploration usage, too. We can
install them all at once by using the `c()` function, which creates a
list. We'll open these packages with the `library()` function later.

```{r}
install.packages(c("nycflights13", "gapminder", "Lahman"))
library(nycflights13)
library(gapminder)
library(Lahman)
```

## Exploration

### Using `dplyr` for Data Exploration

`dplyr` is a powerful package for data manipulation and exploration. It
provides a set of functions that can be used to filter, group, and
summarize data. In this section, we will explore some of the most
commonly used functions in `dplyr`.

A few things about data and data types in R! Like Python, we have
specified types of data we'll use in our tables.

-   int is integer

-   dbl is doubles

-   chr is for character or characters

-   dttm is date-time

-   lgl is logical - similar to Booleans in Python or other programming
    languages; either TRUE or FALSE

-   fctr is factors (We won't use these much yet)

-   date - self explanatory.

### There are five main processes we'll use with dplyr to manipulate our data:

-   `filter()` our data by choosing data by value

-   `arrange()` data by reordering rows

-   `select()` specific data items

-   `mutate()` existing data into new data

-   `summarize()` values into a single summary

Like SQL, we'll use aggregation to break these functions down into
groups; we'll do so by using a `group_by()` function as well.

dplyr functions follow a common syntax: \`function_name(\<data frame\>,
\<\*args\>)\<resulting data frame\>. Many data frames in R are called
'tibbles'. Don't worry too much about what this means for now - just
imagine them like tables in SQL for right now. An example of the dplyr
syntax:

```{r}
filter(flights, month == 3, day == 31)
# ?flights
# View(flights)
```

In the above example, I had two arguments - month == 3, and day == 31.
This filtered down the results to only display flights that occurred on
March 31, which is the day I wrote this (except the `nycflights13` data
is from 2013 - RStudio was only two years old!)

Much like python, we can compare values using comparison operators -
`>`, `<`, `>=`, `<=`, `==`, `!=`. We also get to use & and \| for
comparisons of multiple booleans.

```{r}
carrier_df <- filter(flights, carrier =="AA" | carrier == "DL" | carrier == 'UA')
carrier_df

#View(carrier_df)
```

```{r}
dep_time_df <- filter(flights, dep_time <= 1000 & sched_arr_time >= 1000 & arr_delay != 0)
dep_time_df

#View(dep_time_df)
```

### Arranging Rows

```{r}
arrange(flights, year, month, day, desc(sched_dep_time))

#View(arrange(flights, year, month, day, desc(sched_dep_time)))
```

## Selecting Columns

```{r}
select(flights, year, month, day)
```

We can also use `-` to exclude columns from the selection:

```{r}
select(flights, -carrier)
```

`dplyr` has built in helper functions that can return data to us as well
when used in conjunction with our select statement!

Some examples of these are:

-   starts_with()

-   ends_with()

-   contains()

-   matches() - inside of this, you'll insert a string of Regex

-   num_range("n", 5:7) will match n5, n6, and n7

-   everything() will include all the rest of the columns. So you can
    put it at the end of a select statement as a parameter, and you'll
    be able to move selected columns to the left side, and then include
    the rest of the data.

```{r}
# Select all columns from flights
select(flights, everything())

# Select all columns from flights that start with "c"
select(flights, starts_with("c"))

# Select all columns from flights that end with "p"
select(flights, ends_with("e"))

# Select all columns from flights that contain "g"
select(flights, contains("g"))

# Select all columns from flights that match the regular expression "mp|c"
select(flights, matches("fl|c"))
```

Select can also be used to get columns by index. To do so, we use the
`:` operator we learned about yesterday to specify a range of column
indicies:

```{r}
select(flights, 1:3)
```

### Mutating Data

Besides being a terrifying name, mutating data is an important part of
exploring out data. This function allows us to combine observations from
other columns to create a new column of observations. For example:

```{r}
flight_data <- select(flights,
                      year:day,
                      ends_with('delay'),
                      distance,
                      air_time)

mutate(flight_data,
       gain = arr_delay - dep_delay,
       speed = distance / air_time *60)
```

You can now see the `gain` and `speed` columns have been created;
`mutate()` always places those new columns at the end of the data set,
so if you'd want to move them to the front, you'd use `select()`.

Keep in mind as you do mutations that whatever process you end up using
has to be something that iterates on data sets, and that produces
something iterable as well. \### Transmute Data

Transmutation is when we want to create these new variables in our
dataframe, but only want to return those variables back to us!

```{r}
flight_data <- select(flights,
                      year:day,
                      ends_with('delay'),
                      distance,
                      air_time)

transmute(flight_data,
       gain = arr_delay - dep_delay,
       speed = distance / air_time *60)

```

### Summarizing Data

```{r}
summarize(flights, delay = mean(dep_delay, na.rm=TRUE))
```

First off, this is kind of a weird table. It only has one piece of data
in it! Not especially useful. By the way, the `na.rm = True` line asks
the function to remove any missing values in the data. If we didn't have
it when we use `group_by()`, we'd have a lot of observations reading
`NA`, which isn't very helpful. In our current data set, the delay times
for cancelled flights are populating the database with `NA` values.

Summarizing data is a lot easier if we use `group_by()` with it. This is
very similar to how we use aggregate functions in SQL.

```{r}
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

## In-Class Exercise 1:

Using the built in dataset, `mtcars`; - Select all columns that start
with `'m'` - Select all columns that end with `'g'` - Select all columns
that matches mp or c - Mutate a new column using the `disp` and `cyl`
columns. - Summarize your data!

```{r}

```

### Using Pipe to string together functions

These functions become more and more useful when we can combine them
together - often our exploration will be multi-step. Fortunately,
there's a way we can combine functions together - pipe.

Imagine we want to look at the relationship between distance and average
delay for each location. We'll group flights by destination, figure out
distance, average delay, and number of flights, and then filter out
noise and the airport in Honolulu, which is so far away from other
airports that it will make it hard to see the data we want to focus on.

```{r}
# Code before we use pipe:
by_destination <- group_by(flights, dest)
delay <- summarize(by_destination,
                   count = n(),
                   # n() gives current group size
                   dist = mean(distance, na.rm=TRUE),
                   delay = mean(arr_delay, na.rm=TRUE)
                   )
delay <- filter(delay, count > 20, dest != "HNL")
delay
```

A more efficient way of doing the same thing, where we don't need to
write variables for each step over and over, uses pipe:

```{r}
delays <- flights %>%
  group_by(dest)%>%
  summarize(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm=TRUE)
  ) %>%
  filter(count >20, dest != "HNL")

delays
```

This way, we can simply thread queries together without having to write
new variables every time. It's inferred that each function is working on
the same data frame, so we don't need to write it in as the first
parameter of each function here. It's pretty normal to add a count
function into our code as well, so that we know how large our data sets
are - if we've queried our data down into a very small number of values,
it can be easy to mistakenly draw conclusions based on a very small
amount of data.

Please note: The only part of the tidyverse that won't work with pipe is
ggplot2. You can pipe into it, but you can't pipe afterwards.

```{r}
# Create a variable that we can re-use later that removes all cancelled flights
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(mean=mean(dep_delay))
not_cancelled
```

## In-Class Exercise 2:

Using the `flights` dataset, create your own column, then create a
filter that removes values for carrier where it is equal to 'UA'. Then
group the dataset by the sched_arr_time, summarize the data and View
your data.

```{r}

```

## Visualizations with ggplot2

Now we can look at the plotted data of delay times, and try to learn
something about delay times.

```{r}
delay <-  not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay)
  )
ggplot(data=delays, mapping = aes(x=delay)) + 
  geom_freqpoly(binwidth = 10)
```

This chart makes it look like there are planes with an average delay of
5 hours, which is bizarre. Maybe we're not looking at a large enough
data set! For example - maybe we're working with a small data set, like
if we were only looking at a small number of total flights. Imagine if
this data set were only 100 flights, and one plane had a 10 hour delay,
and no delay on it's second flight. That plane would now appear to have
5 hours of delay on average! Obviously, this is a problem, and we need
to be sure that we don't have too small of a data set.

```{r}
delays <-  not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay, na.rm=TRUE),
    n = n()
  )
  ggplot(data=delays, mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)
```

Now we have a better idea. Let's change the plot parameters so we can
get a better look at the bulk of our data - we have some outliers for
flights that are greatly delayed here, and we can see that the flights
with heavy delays have very few flights to their name. It's possible
these planes had other issues causing their delays, and they didn't do
any other flights.

```{r}
delays %>%
  filter(n > 25) %>%
  ggplot(mapping = aes( x = n, y = delay))+
  geom_point(alpha = 1/10)
```

Looks like the majority of flights leave on time most of the time. This
is a much better data set to look at to find information about the bulk
of flight delays.

Built in to our tidyverse are several data sets that we can play around
with. In the below code block, we create a variable `myplot` and save
the `mpg` database to it.

```{r}
myplot <- mpg
myplot
```

**Something you should be aware of and have open (perhaps on a second
monitor, or you can print them out) is the ggplot2 cheat sheet!**
<https://github.com/rstudio/cheatsheets/blob/main/data-visualization-2.1.pdf>

### QPlot

`Qplot`, or quick-plot, uses inference to build a plot in the quickest,
easiest fashion with little to no code. For example, we can look at the
diamonds dataset and quickly plot the carat and price columns from it

```{r}
qplot(carat,price,data=diamonds)
```

We can see that there is some form of linear relationship here, but with
the way the values currently fall on the graph, we may want to normalize
these values first. Here's how we can do that using the `log()`
function:

```{r}
qplot(log(carat), log(price), data=diamonds)
```

Now, we can clearly see the linear relationship between carat and price!

In another example, we can look at the mtcars dataset and quickly plot
the carb and cyl columns from it

```{r}
qplot(carb, cyl, data=mtcars)
```

#### Arguments

Arguments in ggplot2 can be a combination of already existing variables
as well!

```{r}
qplot(carat, x*y*z, data=diamonds)
```

Some of the basic arguments of `qplot()` are:

-   **Colour:** Using `colour`, we can point towards a column of the
    dataframe object to use as a color.

-   **Size:** Using `size`, we can adjust the size of each data point
    available.

-   **Shape:** `Shape` transforms the appearance of the dots on the
    scatterplot.

-   **Alpha:** `Alpha` refers to the opacity of your dots on the
    scatterplot.

```{r}
qplot(carat, 
      price, 
      data=diamonds, 
      colour=color, 
      size = 1, 
      alpha = 1/100)
```

One thing to note is that the color and shape work well with discrete
data, while size works well with continuous!

```{r}
# create a histogram using qplot for diamond prices
qplot(price, data = diamonds, binwidth = 500) +
  labs(x = "Price", y = "Frequency", title = "Distribution of Diamond Prices") +
  theme(plot.title = element_text(hjust = 0.5))
```

##In-Class Exercise 3:

Using `qplot()`, create a graphic from the diamonds dataset. Write out
an explanation on how that graphic represents some relationship between
independent and dependent variables.

```{r}

```

## Visualizations Cont.

### `ggplot()`

```{r}
View(mpg)
```

```{r}
ggplot(data=mpg) +
  geom_point(mapping = aes(displ, hwy))
```

```{r}
ggplot(data = mpg) + geom_point(mapping = aes(displ, hwy, colour=class))
```

```{r}
ggplot(data = mpg) + geom_point(mapping = aes(displ, hwy, colour=displ))
```

```{r}
ggplot(data = mpg) + geom_point(mapping = aes(displ, hwy, colour=displ < 5))
```

#### Facets

##### What is faceting?

Faceting is a data visualization technique used to display subsets of a
dataset in separate panels or plots. Each panel corresponds to a unique
value or combination of values of a variable, allowing you to examine
patterns and trends across different subgroups of your data.

In ggplot2, faceting is achieved using the `facet_wrap()` or
`facet_grid()` functions. `facet_wrap()` arranges panels in a grid based
on a single variable, while `facet_grid()` arranges panels based on two
variables.

To use faceting, you first need to identify the variable or variables
that you want to use to split your data into subsets. Then, you add the
appropriate facet function to your `ggplot` code and specify the
variable(s) to use for faceting.

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(displ, hwy, shape = drv,colour = rgb(0.7,1.0,.3)))+
  facet_wrap(~ class, nrow = 3)
```

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(jitter(displ), hwy, shape = drv, colour = rgb(0.7, 1.0, 0.3))) +
  facet_wrap(~ class, nrow = 3) +
  scale_shape_manual(values = c(1, 2, 3)) +
  xlab("Engine Displacement (L)") +
  ylab("Highway Miles per Gallon (mpg)") +
  theme(axis.text.x = element_text(size = 10, color = "blue"),
        axis.text.y = element_text(size = 10, color = "red"),
        legend.position = "bottom")
```

```{r}
ggplot(data=mpg) +
  geom_point(mapping = aes(displ, hwy, color = class))+
  facet_grid(drv ~ .)
```

```{r}
ggplot(data=mpg) +
  geom_point(mapping = aes(displ, hwy, color = class))+
  facet_grid(drv ~ .) + 
  ggtitle("Highway MPG vs Engine Displacement") +
  xlab("Engine Displacement (L)") +
  ylab("Highway MPG")+
  theme(legend.position = 'bottom',
        legend.text = element_text(size = 10))
```

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")
```

```{r}
ggplot(data = mpg) + 
  geom_smooth(mapping=aes(displ, hwy, linetype=drv))+
  geom_point(mapping = aes(displ, hwy, color = drv))
```

```{r}
ggplot(mpg, aes(displ, hwy, linetype=drv)) +
  geom_point((aes(colour = class))) + 
  geom_smooth(se=FALSE)
```

```{r}
ggplot(diamonds)+
  geom_bar(aes(cut))
```

Whoa, where'd count come from? **Count is not a variable or attribute of
the variable diamonds!** Count comes automatically with a lot of graphs
as an attribute. You can verify what I'm saying with `?diamonds` in the
console.

Any attribute of a data set that is algorithmically calculated is called
a *stat*, which is short for a statistical transformation. Many of the
**geom** functions have stats built in, and many stats display geoms.
For example, the above code block used a geom, but this one uses a stat,
and results in an identical chart:

```{r}
ggplot(diamonds) +
  stat_count(aes(cut))
```

Let's add color here!

```{r}
ggplot(data = diamonds)+
  geom_bar(aes(cut, color=cut))
```

```{r}
ggplot(data = diamonds)+
  geom_bar(aes(cut, fill=cut))
```

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
```

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = "identity")

```

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = "identity")
```

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
```

#### Pie Chart

What if I wanted to add an additional variable to my graph as well as
change the graphic into a pie chart?

```{r}
pie = ggplot(diamonds) + 
  geom_bar(aes(cut, fill = clarity),
           position = 'fill') +
  theme(aspect.ratio = 1) +
  labs(x=NULL, y=NULL)

pie + coord_polar()
```

```{r}
pie = ggplot(diamonds) + 
  geom_bar(aes(cut, fill = clarity),
           position = 'dodge') +
  theme(aspect.ratio = 1) +
  labs(x=NULL, y=NULL)

pie + coord_polar()
```

#### In-Class Discussion

Is this a good graphic? Why? What information is being returned to us
and how is it useful?

```{r}

```

#### Box-Plots

to generate a box-plot, we can use the `geom_boxplot()` function in
conjunction with our `ggplot()` library

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()
```

#### Customizing a box-plot

To customize a box-plot, we have a few different options!

-   `coord_flip()`: flips x/y axis

-   

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot(fill = "#336699", color = "#336699", alpha = 0.7) +
  geom_jitter(width = 0.2, height = 0, color = "#FFA500", alpha = 0.7)+
  labs(title = "Highway Miles per Gallon by Car Class", x = "Car Class", y = "Highway Miles per Gallon") +
  theme_bw()+
  coord_flip()
```

## In-Class Exercise 4:

Using ggplot2, create a custom graphic using the `Lahman` built-in
dataset we loaded earlier this lecture. Your graphic should be proceeded
with data exploration as well as a hypothesis about the data before
creating the graphic. Your graphic should include colors, a title for
all axes and for the graphic itself.

```{r}

```

```{r}

```

## Vizulations Cont.

#### Map Data

```{r}
nz <- map_data("nz")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black")
```

```{r}
ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap()
```

#### Customize a map

```{r}
ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap() +
  ggtitle("Map of New Zealand") +
  labs(x = "Longitude", y = "Latitude") +
  theme(axis.title = element_text(size = 12))
```

### Task : 

Find a built-in data set you would like to explore. Explore the data set
and use the cheat sheet you built to label continuous and discrete data.
Analyze the data set using dplyr, create graphs, mutate two columns, and
formulate a hypothesis about your data.

```{r}
library(dplyr)
data(mtcars)
str(mtcars)

```

```{r}
# Selecting a subset of columns
mtcars_select <- select(mtcars, mpg, cyl, hp, wt, qsec, gear)

# Filtering rows based on a condition
mtcars_filtered <- filter(mtcars_select, cyl == 4)

# Grouping the data by number of gears
mtcars_grouped <- group_by(mtcars_filtered, gear)

# Summarizing the data by calculating the mean of each variable
mtcars_summarized <- summarize(mtcars_grouped,
                                mean_mpg = mean(mpg),
                                mean_hp = mean(hp),
                                mean_wt = mean(wt),
                                mean_qsec = mean(qsec))

# Arranging the data by descending order of mean mpg
mtcars_arranged <- arrange(mtcars_summarized, desc(mean_mpg))

# Creating a bar graph of mean mpg by number of gears
library(ggplot2)
ggplot(mtcars_arranged, aes(x = factor(gear), y = mean_mpg)) + 
  geom_bar(stat = "identity") +
  xlab("Number of gears") +
  ylab("Mean MPG") +
  ggtitle("Mean MPG by Number of Gears")

```

```{r}
mtcars_mutated <- mutate(mtcars, wt_lbs = wt * 2205)

```

```{r}
ggplot(mtcars_mutated, aes(x = wt_lbs, y = hp)) +
  geom_point() +
  xlab("Weight (lbs)") +
  ylab("Horsepower") +
  ggtitle("Horsepower vs Weight (lbs)")

```

```{r}
mtcars_filtered <- filter(mtcars, am == 1)

```

```{r}
mtcars_grouped <- group_by(mtcars_filtered, cyl)

mtcars_summary <- summarize(mtcars_grouped,
                            mean_hp = mean(hp),
                            mean_mpg = mean(mpg))

```

```{r}
library(ggplot2)

ggplot(mtcars_summary, aes(x = factor(cyl), y = mean_hp, fill = "Horsepower")) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_bar(aes(x = factor(cyl), y = mean_mpg, fill = "MPG"), stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("#0072B2", "#F0E442")) +
  xlab("Number of Cylinders") +
  ylab("Mean Value") +
  ggtitle("Mean Horsepower and MPG by Number of Cylinders")

```

```{r}
mtcars_mutated <- mutate(mtcars, wt_lbs = wt * 2205, hp_wt_ratio = hp / (wt_lbs / 1000))

```

```{r}
ggplot(mtcars, aes(x = hp, y = mpg)) +
  geom_point() +
  xlab("Horsepower") +
  ylab("Miles per gallon") +
  ggtitle("Horsepower vs. Miles per gallon")

```

```{r}
ggplot(mtcars, aes(x = mpg)) +
  geom_histogram(binwidth = 3, fill = "steelblue", color = "white") +
  xlab("Miles per gallon") +
  ylab("Frequency") +
  ggtitle("Distribution of miles per gallon")

```

```{r}
ggplot(mtcars, aes(x = mpg, fill = factor(cyl))) +
  geom_density(alpha = 0.5) +
  xlab("Miles per gallon") +
  ylab("Density") +
  ggtitle("Density of miles per gallon by number of cylinders")

```

```{r}

```

Based on the analysis and visualization of the "mtcars" data set, we can
formulate several hypotheses. One possible hypothesis is that there is a
negative correlation between horsepower and miles per gallon, meaning
that as horsepower increases, miles per gallon decreases. This could be
due to the fact that more powerful cars typically have larger engines,
which consume more fuel. We can test this hypothesis by calculating the
correlation coefficient between horsepower and miles per gallon and
performing a hypothesis test to determine if the correlation is
statistically significant.

Another hypothesis is that the number of cylinders in a car is related
to both its horsepower and miles per gallon. Cars with more cylinders
may have higher horsepower, but lower fuel efficiency due to their
larger engines. We can test this hypothesis by analyzing the
relationship between number of cylinders, horsepower, and miles per
gallon, and performing a regression analysis to determine the impact of
each variable on the others.

Overall, the "mtcars" data set provides a rich set of data for exploring
and analyzing the relationships between various automotive features, and
there are many possible hypotheses that can be tested based on this
data.

```{}
```
